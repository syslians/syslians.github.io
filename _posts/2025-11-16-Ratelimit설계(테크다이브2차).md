
## 테크다이브 시스템 디자인 2차(Rate limit 설계)

### Rate Limit이란?
이 메커니즘을 이야기하면 Throtlling이랑 비교를 해볼수 있을 것 같다. 넓은 의미에서 보면 비슷한 맥락이다. 
결국에 부하가 특점 임계치나 기준을 넘으면 의도적으로 성능을 떨어뜨려 서버나 하드웨어 자원을 보호하는것. 이것이 쓰로틀링. 사실 넓은 의미에서 보면 비슷한 맥락이기도 합니다. 

시간단위로 속도나 요청횟수를 제한 -> Rate Limit
정책적으로 사용자를 차단한다면 Access Control

즉, DDos, 웹 스크랩퍼 봇등을 차단하는것이 주 목적. 
- 초당 3회 이상 새 글 작성 금지
- 같은 IP 주소로는 하루에 10개 이상 계정 생성 금지
- 같은 디바이스로는 주당 5회 이상 리워드 요청 금지.
- 혹은 토큰을 확인해서 구독자가 아닌 사용자는 특정 페이지에 접근하지 못하게 한다던지

### 기능적 요구사항과 비기능적 요구사항
- API 호출 제한 (분당 100회, 시간당 1000회)
- 낮은 응답시간
- 가능한 한 적은 메모리 사용
- 분산 서버
- 예외 처리
- 높은 결함 감내성

### 비기능적 요구사항
- 낮은 지연시간 (< 30ms)
- 높은 가용성 (99.9%+)
- 확장성 (초당 수백만 요청 처리)
- 정확성 vs 성능의 트레이드오프 고려
- DAU 100만 QPS, TPS
- 1명당 100건 피크타임 4000만.
- TPS p99 10ms

### Rule 식별
- ID 식별
- IP 식별
- ROLE - 1. Admin, 2. Prmium
- Global Counter


### 이 Rate Limiter는 어디에 둘 것인가?
먼저 시스템이 단일 서버냐, 분산 서버냐를 먼저 가정을 해봐야 할 것 같습니다. 

이 Rate Limit은 어디서 구현되어 있느냐. 클라이언트에 구현하느냐 아니면 서버에 구현하느냐. CDN에 두느냐

 혹은 미들웨어나 Reverse Proxy에 두느냐. 혹은 더 나가서 Router나 Switch에서도 대역폭 기준으로 Rate Limit을 설정할 수도 있습니다. 

 Reverse Proxy라면 Nginx, AWS면 AWS API Gateway, ELB, ALB. 

혹은 방화벽에도 내장되어있을수도 있겠죠.

또는 애플리케이션 레벨에서, 네트워크 레벨에서, 하드웨어 레벨에서 구현되어 있을수도 있다. 복잡성을 줄이기 위해 Reverse Proxy로 Nginx를 쓰고,
내장되어있는 Rate Limit을 쓰기로 함. 분산 서버라는 가정하에 Reverse Proxy에 구성. 애플리케이션 레벨에서 배치.  

### 분산 환경에서 구현시 문제점
여러개의 서버들이 컨테이너, 혹은 가상머신에 분산되어 여러 서버, 혹은 데이터센터, 리전에서 동작하고 있는 경우에는 Global Rate limiter가 필요합니다.  어떻게 해야할까요? 

1. **Sticky session**: 로드밸런서에 Sticky Session을 두고 유저는 특정 node로만 request를 가도록 해서, local rate limiter를 활용하도록 한다. 하지만 이렇게 구현하면 스케일링이 불가능합니다. 가용성도 없죠.
2. **Centralized Data Store**: Redis나 Cassandra같은 중앙화된 data store를 사용해서 rate limite 정보를 저장할 수 있습니다. 하지만 이 경우에는 지연시간이 문제가 될 수 있지만, 분산환경에 최적화되어 있기 때문에 좀 더 graceful 한 해결책이 될 수 있다.

먼저 분산환경에서의 Centralized Store는 Race Condition, Concurrency 문제와 Synchronization 문제가 있다. 각 노드에서 동시에 같은 Counter를 저장하려는 경우 Counter가 증가하지 못하는 문제가 발생할 수 있다.
이를 위해 read-write operation lock을 활용할 수 있지만, Lock은 성능 문제가 발생할 수 있다.

![BitOperations](assets/img/favicons/Screenshot-2025-11-08-5.19.45.png)

많은 Globlal lock으로 인한 Latency를 줄이기 위해, Local memory에 rate를 업데이트 하고, 주기적으로 Centralized store와 동기화하는 방식입니다. 이 아키텍쳐의
포인트는 Local Memory와 Centralized database와의 Inconsistency를 해결해주는 synchroniazation service가 별도로 있어야 한다는 점입니다.

### 고처리량 분산 시스템 rate limit
요즘 아키텍쳐는 많은 기업들이 마이크로서비스를 컨테이너에 올려서 배포를 합니다. 이런 분산 시스템에서는 모든 인스턴스가 같은 처리를 담당하기 때문에 중앙 저장소로
상태를 저장하는 방식을 많이 채택을 합니다.

### 중앙 저장소 비율 제한기
이를 가장 간단하게 구현한다면 API 제공자당 하나의 카운터를 저장하는 방식으로 구현할 수 있을것 같습니다. 카운터는 API 제공자에게 요청할때마다 하나씩 증가하며
1초가 경과하면 리셋됩니다. 카운터값은 현재 초 내에서 요청된 횟수를 나타내며, rate limit에 도달했는지 여부를 결정하는데 사용할 수 있습니다.

이 방법은 처리량이 많지 않은 시스템을 위한 간단하면서도 효율적인 해결책이지만, 확장이 쉽지 않습니다. 설계상 Redis의 단일 카운터는 시스템의 병목이 되어 버립니다.
더구나 모든 rate limit 카운팅을 처리하는 단일 노드는 단일 장애지점이 되어버립니다. 복제를 했더라도 즉시 fail over 되지 않고 fail over process가 완료
될때까지 모든 API 소비자가 차단되는 것은 좋은 방법이라고 하기 어렵습니다.

이 방법은 API 요청마다 각각 Redis 접속이 필요하기 때문에 각 요청의 총 지연시간이 불가피하게 증가합니다. 이는 대규모 트래픽을 감당해야 하는 대규모 시스템에서는
어울리지 않는 솔루션일 수 있습니다. 그렇다면 그 대안은?

### 분산형 인 메모리 비율 제한기
중앙화된 저장소 방식의 대안으로 분산형 인 메모리 Rate Limit이 있습니다. 제공자 API Rate limit을 소비자 인스턴스에 분할, 할당하여 각자 요청을 제어할 수 있도록
만드는 것입니다. 

이를 구현하기 위해 각 소비자 인스턴스는 자신에게 할당된 Rate Limit을 알아야 합니다. 만약 트래픽이 각 소비자 인스턴스로 잘 분산된다면 아래와 같은 방법으로 계산할 수 
있습니다.

```Latex
ConsumerInstanceRateLimit = \frac{TotalRateLimit}{NumberOfConsumerInstances}
```

실제 상황에선 애플리케이션이 실행되는 도중 애플리케이션이 실행되는 도중 이 변숫값들이 바뀔 수 있습니다. 예를 들어 서버 에러나 서버 확장 작업 때문에 소비자 인스턴스의 수가 바뀔수 있고, 제공자 측에선 가용성 문제가 발생하면 총 비율 한도도 변경될 수 있습니다.
.바로 이런 이유로 설정 서버를 시스템에 도입할 수도 있겠죠. 설정 서버는 각 API 제공자에 대한 총 비율 한도와 소비자 인스턴스 수를 관리하고 제공하며 애플리케이션을 재시작하지 않고 이런 변수의 값들을 수정할 수 있음.
![BitOperations](assets/img/favicons/image.png)

설정 서버로는 Central Dogma와 같은 것들이 있을수 있습니다. 소비자 인스턴스는 시작할때 Central Dogma의 데이터로 초기화되며, 설정 서버에서 변경 사항을 통지하면
업데이트 됩니다. API 소비자 인스턴스에겐 각각 Rate Limit이 주어지며, 제공자에게 보내는 모든 요청의 합계가 할당된 Rate Limit을 초과해서는 안됩니다. 이를 위해선
모든 소비자 인스턴스가 제대로 동기화되면서 time window가 시작하고 끝나는 시간에 합의해야 합니다. 이 문제를 해결하기 위해 well-clock과 엄격히 연결된 time window
를 사용합니다. 실제 well-clock의 초가 바뀔때마다 각 소비자 인스턴스의 요청 카운터가 리셋됩니다.

![BitOperations](assets/img/favicons/Decentralized2.png)

이 시스템이 잘 작동하기 위해서는 서버의 시간 프로토콜을 사용해 동기화되어야 합니다. 다만 그렇게 한다고 하더라도 완벽한 동기화가 보장되는 것은 아님. 
네트워크의 복잡성은 최악의 경우 100Ms 이상의 오류를 발생시킬 수 있기 때문.

|중앙 저장소|분산 인메모리|
|----------|--------------|
|요청을 분산할 필요가 없다| 높은 처리량을 제공할 수 있다|
| 비율 한도를 최대한 사용할 수 있다|지연 시간이 증가하지 않는다|
|DB 요청 때문에 지연시간이 증가한다|트래픽이 균등하게 분산되지 않느다면 비율 한도를 최대한 활용하지 못한다|
|확장하기 어렵다|시스템 시계 동기화가 필요하다|
|단일 장애 지점 발생|소비자 인스턴스 수를 관리하기 위해 추가 설정 시스템이 필요| 

### Rate limit의 기준은?
그렇다면 이 클라이언트를 어떻게 식별하고 기준을 세우느냐에 따라서 또 달라진다. IP를 기준으로 하느냐, request를 기준으로 하느냐, 토큰ID를 기준으로 하느냐, 혹은 전송계층에서는 패킷 기준으로 할수도 있겠죠.

예를 들어, 대상을 정했으면, 필터링 기준을 세워야 합니다. IP를 기준으로 1초에 100번 요청이 들어오면 차단.

이런 Rule들은 개발자나 관리자가 설정할 수 있다.

### Token Bucket Algorithm
대표적인 구현체로는 자바의 Bucket4j.

토큰 버킷은 지정된 용량을 갖는 컨테이너이너. 이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워집니다. 토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 않습니다. 
토큰 공급기는 이 버킷에 매 2초마다 토큰을 추가. 버킷이 가득차면 추가로 공급된 토큰은 버려짐. 이 버킷은 무엇일까요? 메모리입니다.


각 요청은 처리될때마다 하나의 토큰을 사용합니다. 그러니까 request마다 token이 1:1로 삭제되도록 구성되어 있는거죠. 요청이 도착하면 버킷에 충분한 토큰이 있는지 검사. 

- 충분한 토큰이 있는 경우, 버킷에서 토큰 하나를 꺼낸 후 요청을 시스템에 전달.
- 충분히 토큰이 없는 경우, 해당 요청은 drop.

이 토큰 버킷 알고리즘은 2개의 파라미터를 받습니다.

- Bucket Capacity: 버킷에 담을 수 있는 토큰의 최대 개수
- 토큰 공급류리 초당 몇개의 토큰이 버킷에 공급되는가

버킷은 몇개사용? 엔드포인트마다 사용. 예를 들어 트위터에서 사용자가 하루에 한 번 포스팅, 친구는 150명, 좋아요는 다섯번까지 누를 수 있다면 사용자마다 3개의 버킷을 두어야 할 것.

IP 주소별로 rate limit을 적용해야 한다면 IP 주소마다 버킷을 하나씩 할당해야 한다.

시스템 처리율을 초당 10.000개 요청으로 제한하고 싶다면 모든 요청이 하나의 버킷을 공유하도록 설정

- 장점

구현이 쉬움, 메모리 사용 측면에서 효율적. 짧은 시간 집중되는 트래픽도 처리 가능. 

- 단점

이 알고리즘은 Bucket Capacity와 Token 공급률이라는 두 개의 인자를 가지고 있는데 적절하게 튜닝하는 것은 까다로운 일이 될 것.

### Leaky Bucket Algorithm
Leaky Bucket은 Token Bucket의 반대로 구현되어 있다고 보면됨. Token Bucket은 미리 용량을 설정하고 토큰을 가득 채운 뒤 하나씩 빼는거고, Leaky Bucket은 비슷하지만 반대로 하나씩 토큰이 채워짐. 요청 처리율이 고정되어 있슴. 보통 FIFO queue로 구현. 

그림으로 보면 구멍이 뚫린 양동이 예시가 있죠. 비슷하게 수도꼭지를 생각하는 것도 이해가 빠를것입니다. 마개를 닫지 않고 수도꼭지를 세개 튼다면 빠지는 속도 < 차는 속도 가 더 빠르기 때문에 금방 가득 찰것이고. 추가적인 물은 흘러넘치겠죠. Leaky Bucket은 이 흘러넘치는 물들을 차단합니다.
- 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우 큐에 요청을 추가
- 큐가 가득 차 있는 경우에는 새 요청을 버려짐
- 지정된 시간마다 큐에서 요청을 꺼내어 처리함.

Leaky Bucket 알고리즘은 아래 두 개의 인자를 받는다.

- 버킷 Size: 큐 사이즈와 같은 값. 큐에는 처리될 항목들이 보관
- 처리율(overflow rate): 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값. 보통 초 단위로 계산

Shopify에서 해당 알고리즘에 구현되어 있음

장점

- 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
- 고정된 처리율을 갖고 있기 때문에 안정적 출력이 필요

단점

- 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고, 그 요청들을 제때 처리하지 못하면 최신 요청들은 버려지게 됨
- 두 개 인자를 갖고 있느데, 이들을 올바르게 튜닝하기 까다로울 수 있음

### 고정 윈도우 카운터 알고리즘
- 타임라인을 고정된 간격의 윈도우로 나누고, 각 윈도우마다 카운터를 붙인다.
- 요청이 접수될때마다 이 카운터의 값은 1씩 증가한다.
- 이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도우가 열릴때까지 버려진다.

이 알고리즘의 가장 큰 문제는 윈도우의 경계 부근에 순간적으로 많은 트래픽이 몰릴 경우 윈도우에 할당된 양보다 더 많은 요청이 처리될 수 있음.

장점

- 메모리 효율 좋음
- 이해하기 쉽다
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.

### 이동 윈도 로깅 알고리즘
고정 윈도 카운터 알고리즘에는 중대한 문제가 있다. 윈도 경계 부근에 트래픽이 집중되는 경우 시스템에 설정된 한도보다 많은 요청을 처리하게 되는 것. 
이동 윈도 로깅 알고리즘은 이 문제를 해결한다. 

- 이 알고리즘은 요청의 타임스탬프를 추적. 타임스탬프 데이터는 보통 레디스의 정렬 집합(ZSET) 같은 캐시에 보관
- 새 요청이 오면 만료된 타임스탬프는 제거한다. 만료된 타임스탬프는 그 값이 현재 윈도우의 시작 시점보다 오래된 타임스탬프를 말한다.
- 새 요청의 타임스탬프를 로그에 추가
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달. 그렇지 않은 경우에는 처리를 거부.

### Redis 명령 흐름 (원자성 보장 Lua 버전)

```Redis
-- KEYS[1] = zest key, ARGV[1] = now(epoch seonds), 
-- ARGV[2] = window_secs, ARGV[3] = limit

local now         = tonumber(ARGV[1])
local window_sec  = tonumber(ARGV[2])
local limit       = tonumber(ARGV[3])

-- 1) 오래된 로그 제거: (now - window, -inf]
redis.call('ZREMRABGEBYSCORE', KEYS[1], 0, now -window_sec)

-- 2) 현재 카운트 조회
local cnt = redis.call('ZCARD', KEYS[1])

if cnt >= limit then
	return 0
end

-- 3) 이번 요청 타임스탬프 삽입 (score=now, member=unique-id)
-- member는 now..random 등으로 충돌 방지
redis.call('ZADD', KEYS[1], now, now .. '-'..redis.call('INCR', KEYS[1]..':seq'))

--4) 키 유지비용 방지: 윈도우 만큼 TTL 부여
redis.call('EXPIRE', KEYS[1], window_sec)

return 1

```

장점

- 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다. 어느 순간의 윈도우를 보더라도, 허용되는 요청의 갯수는 시스템의 처리율 한도를 넘지 않는다.

단점

- 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청이의 타임스탬프도 보관하기 때문. 가장 정확하지만 메모리가 터질 수 있음

윈도우 길이 T와 QPS가 크면, ZSET에 원소가 T * QPS 만큼 쌓입니다.
- Ex: T = 60초, QPS=10k -> ZSET ~60만 원소. 사용자별/엔드포인트별로 키가 늘면 총합이 기하급수적으로 증가
- ZSET은 score(타임스탬프) + member(문자열) + 내부 인덱싱 구조(스킵 리스트/해시)의 오버헤드가 커서 원소 수가 곧 메모리가 됩니다.
- 정확성 = 모든 요청 로그 저장의 대가가 메모리/CPU(정리/삭제)비용으로 돌아옴.

결론: 정확도 최상이지만, 비용이 매우 큼. 고 QPS. 대량 키 환경에서는 감당하기가 힘들수도 있다.

### Sliding Window Counter
슬라이딩 윈도우 알고리즘이 고정크기 N 크기의 윈도우가 포인터 시작점과 끝점을 유지한채로 +1 씩 증가시키면서슬라이딩 하는 방식이라면, 이 방식은 

슬라이딩 윈도우 알고리즘 카운터는 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것. 이 알고리즘을 구현하는데는 두 가지 접근법이 사용됨.

### Sub Window 합산 (버킷화)
최근 60초를 작은 버킷(예: 1초 또는 10초)들로 쪼개어서 저장하고, 마지막 N개의 버킷 합으로 근사.

스키마:
- 키: rate{user}:{bucket_ts}{bucket_t s= now // BUCKET_SIZE}
- 값: 해당 버킷 내 요청수 (String)
- TTL: BUCKET_SIZE * NUM_BUCKETS (최근 윈도우 범위만 유지)

Redis 파이프라인 흐름
```Redis
BUCKET_SIZE = 10        # 10초 버킷
WINDOW_SEC  = 60        # 최근 60초 제한
NUM_BUCKETS = WINDOW_SEC // BUCKET_SIZE. # 6

now         = int(time.time())
bucket      = now // BUCKET_SIZE
user_key    = "user123"

# 1) 최근 NUM_BUCKETS 개의 버킷 키 만들기
keys = [f"rate:{user_key}:{bucket - i}" for i in range(NUM_BUCKETS)]

# 2) 합산하여 현재 사용량 파악
pipe = r.pipeline()
for k in keys:
	pipe.get(k)
counts = pipe.execute()
total  = sum(int(c or 0) for c in counts)

# 3) 한도 체크
if total >= LIMIT:
	deny()
	
# 4) 현재 버킷 증가 + TTL 연장
cur_key = f"rate:{user_key}:{bucket}"
pipe = r.pipeline()
pipe.incr(cur_key)
pipe.expire(cur_key, BUCKET_SIZE * NUM_BUCKETS)
pipe.execute()
allow()
```

특성 오차
- 오차 범위: 최대 1개 버킷 크기(BUCKET_SIZE)만큼 시간 경계가 뭉특해짐(BUCKET_SIZE) = 1 초면 오차 매우 적음(정확도 높음).but ket 수 증가

- 장점: 로그 전체를 저장하지 않으니 메모리.CPU 부담 급감
- 단점: 로그 방식 대비 정확도는 근사(정밀 타임스탬프가 아닌 버킷화)

최적화

- MGET 대신 pipeline GET → 네트워크 왕복 비용 절감.
- 버킷을 HASH 한 개에 담아 HINCRBY + HMGET 로 관리해 키 폭증 억제

### Two-bucket 선형보간 (가장 가벼운 근사)
현재 버킷과 이전 버킷 두 개만 들고, 겹치는 구간을 선형보간으로 환산.

개념
- T=60초, BUCKET=1초(또는 10초)
- prev_count(직전 버킷), curr_count(현재 버킷), 그리고 현재 버킷 경과비율 `α`(0~1).
- 근사치 = curr_count + prev_count * (1 - `α`) (직전 버킷에서 최근 T초 겹치는 비율만큼만 기준)

Redis 흐름

- INCR rate:{user}:{curr_bucket}
- GET rate:{user}:{prev_bucket}
- 근사치 > LIMIT 이면 거부

장점: 키 2개 조회 + 1개 INCR로 끝나는 초경량.

단점: 정확도는 더 낮음(하지만 대부분의 실서비스에서 충분히 합리적)

### 공통 운영 팁
- Lua로 원자화: “읽고-검사하고-증가”를 하나의 스크립트로 묶어 경쟁 조건 방지.
- TTL 철저: 윈도우 범위를 벗어난 데이터는 반드시 자동 만료.
- 관측성: 429 비율, 평균/95퍼센트 응답시간, Redis CPU/latency 모니터링
- 한계 명시: 로그 방식은 메모리. 카운터 방식은 정확도. 정책에 맞게 트레이드 오프 선택.


1. 문제 수용: 고정 윈도우는 경계에서 2배 버스트가 가능 → 최근 T초 기준으로 바꿔야 한다.
2. 정확도 최우선(Log): ZSET에 모든 요청 시간 저장 → 경계 문제 해소 완벽. 하지만 메모리/CPU 폭증
3. 현실 타협(Counter-subwindow): 버킷화하여 마지막 N개만 합산 → 정확도 약간 손실. 성능,비용은 대폭 상승
4. 더 가볍게(Two-bucket): 현재/직전만 보간 → 초경량, 근사 허용 가능한 곳에 적합
5. 운영 완성: Lua로 원자화. TTL/샤딩/모니터링으로 프로덕션에 안전하게 투입


```
-- KEYS[1] = current bucket key (e.g., rate:user:bucketTs)
-- ARGV[1] = now, ARGV[2] = BUCKET_SIZE (sec), ARGV[3] = WINDOW_SEC, ARGV[4] = LIMIT, ARGV[5..] = previous bucket keys...
-- return 1 allow / 0 deny

local now         = tonumber(ARGV[1])
local bucket_size = tonumber(ARGV[2])
local window_sec  = tonumber(ARGV[3])
local limit       = tonumber(ARGV[4])

-- 1) 합산
local total = 0
for i = 5, #ARGV do
  local v = redis.call('GET', ARGV[i])
  if v then total = total + tonumber(v) end
end

if total >= limit then
  return 0
end

-- 2) 현재 버킷 증가 + TTL
local cur = redis.call('INCR', KEYS[1])
redis.call('EXPIRE', KEYS[1], window_sec)

-- 3) 증가 후 재검(선택)
if (total + 1) > limit then
  -- 롤백할지 말지는 정책에 따라
  return 0
end

return 1

```
호출시 애플리케이션에서 현재 버킷 1개를 KEYS로, 최근 N - 1개의 버킷 키를 ARGV로 넘겨 합산.

### 언제 무엇을 쓰느냐?
- 정확도가 절대적이고 QPS/key 수가 작다 → Log
- 일반적인 웹 API(다수 사용자, 중간 QPS) → Sub-window Counter(1 ~ 5초간 버킷)
- 초저비용.초고성능이 필요, 약간의 오차 허용 → Two-bucket 선형 보간
- (Rate Smoothing+burst 허용이 목표) → Token Bucket/Leaky Bucket 고려


### 논 블로킹 고처리량 Rate limit 구현

### 논블로킹 Rate Limit 구현

리액티브 프로그래밍 패러다임이 서버측에서 인기가 있죠. 블로킹 방식의 구현은 일반적으로 DB 요청이나 네트워크 호출과 같은 I/O 작업을 처리하는 애플리케이션에서는 자원 낭비가 발생할 수 있습니다. 
자바 기반 비동기 웹 서비스 프레임워크인 Armeria와 비동기 리액티브 스트림 처리 라이이브러리인 RxJava2 가 있습니다.


출처: https://engineering.linecorp.com/ko/blog/high-throughput-distributed-rate-limiter, https://smudge.ai/blog/ratelimit-algorithms,
https://smudge.ai/blog/ratelimit-algorithms

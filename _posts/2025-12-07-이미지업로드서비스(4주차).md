---
layout: post
title: "이미지 업로드 서비스"
date: 2025-07-27 22:00:00 +0900
categories: Image Upload Service, aws, S3, file upload, System Design]
author: cotes
published: true
---

## 이미지 업로드 서비스 설계 논의

### 서비스 요구사항

- 이미지 업로드 기능 제공 - 상품이미지, SNS 이미지 등 포괄적인 이미지 업로드 서비스
- 이미지 크기 제한 설정 필요
- 이미지 압축 및 가공 기능
- 이미지 원본 보존 고려

### 비기능 요구사항 정의

- DAU(일일 활성 사용자): 1천만 명
- 일일 업로드 이미지: 약 100만 개 (DAU의 2% 가정)
- 이미지 평균 크기: 최대 10MB
- 일일 스토리지 필요량: 약 10TB
- 업로드 시간: 최대 10초 이내
- 읽기 QPS: 11,574 (일일 10억 조회 기준)
- 쓰기 QPS: 약 11.6

### 시스템 설계

- 이미지 저장소로 Object Storage(S3) 선택
- DB 대신 Object Storage를 선택한 이유:
    - 대용량 이미지 저장에 최적화되어 있음
    - 서버 부담 경감
    - 스케일 아웃 시 파일 동기화 문제 해결
    - 인스턴스 간 파일 접근성 문제 해결

### 이미지 업로드 흐름

- Pre-signed URL 방식 채택
    - 클라이언트가 서버에 업로드 요청
    - 서버가 S3에 가짜 객체 생성 후 Pre-signed URL 발급
    - 서버가 메타 정보를 DB에 저장하고 클라이언트에 URL 전달
    - 클라이언트가 URL을 통해 S3에 직접 파일 업로드

### 최적화 및 고려사항

- 메타데이터 저장 처리의 비동기화 고려
- 메타데이터 정합성 유지 방안:
    - S3 이벤트 노티피케이션 활용
    - 메타데이터 상태 관리(pending, completed)
    - 배치 작업을 통한 정합성 확인
- CDN 활용으로 이미지 제공 성능 향상
- 서버 부하 분산을 위한 클라이언트-S3 직접 업로드

### 고도화 방안

- 이미지 후처리 로직 추가
- 다양한 해상도의 썸네일 자동 생성
- 이미지 압축 기능
- 다양한 파일 타입(PNG, JPG 등) 지원 방안
- 중복 이미지 처리 고려

### 액션 아이템

- [ ]  S3 기반 이미지 저장소 설계 상세화
- [ ]  Pre-signed URL 방식의 업로드 플로우 구현
- [ ]  메타데이터 정합성 유지 방안 구체화
- [ ]  이미지 후처리(압축, 썸네일 생성) 로직 설계
- [ ]  CDN 연동 방안 검토

## 이미지 시스템 설계: 저장, 중복 및 트래픽 관리

### 이미지 처리 전략

- 이미지 처리 시 중요한 트레이드오프: 미리 가공해서 저장하면 조회가 빠르지만 용량이 커지고 불필요한 데이터가 생길 수 있음
- 레디스의 TTL 관리 방식처럼 하이브리드 접근법 고려: 일부는 미리 처리하고 나머지는 조회 시점에 처리
- 예시: 4K 원본 이미지를 가지고 있다가 기기에 맞는 200x200 같은 작은 크기로 요청 시 실시간 변환
- CDN 캐싱 활용: 한 번 요청된 크기의 이미지는 CDN에 캐싱하여 다음 요청 시 빠르게 제공
- 처음 요청 시에는 처리 시간이 필요해 응답이 느릴 수 있음

### 중복 업로드 처리

- 두 가지 중복 상황 논의: 네트워크 중복(동일 이미지 중복 업로드)과 컨텐츠 중복(다른 게시물에 같은 이미지)
- 컨텐츠 중복: 허용되는 중복으로, 다른 유저가 동일 이미지를 올리는 상황
- 네트워크 중복: 사용자가 실수로 같은 이미지를 두 번 올리는 경우
- 해시 함수를 사용해 파일 내용 기반 해시값 생성하여 중복 확인
- 메타데이터에 해시값 저장해 조회 시 활용, 프리사인드 URL에도 활용 가능
- 네트워크 중복 방지를 위해 멱등성(idempotency) 키 활용
- 클라이언트가 멱등키를 전송하고 서버에서 분산 락으로 관리
- UUID로 멱등키 생성하고 레디스를 통해 락 설정, 이를 통해 명등하게 처리

### 트래픽 스파이크 대응

- 갑작스런 트래픽 증가 시(예: 프로모션으로 이미지 업로드 급증) 병목 현상 발생 가능성
- S3는 자동 스케일링으로 높은 트래픽 처리 가능하지만, 메타데이터 DB가 병목될 가능성
- 레이트 리미터 적용 고려: 리키 버킷(Leaky Bucket) 알고리즘 활용
- 서킷 브레이커(Circuit Breaker) 패턴 도입: 과부하 시 레디스로 우회 저장 후 나중에 동기화

### S3 최적화

- S3 제한사항: 특정 프리픽스(prefix)로 초당 3,500개 PUT 요청까지만 처리 가능
- 해시 기반 프리픽스로 파티셔닝하여 트래픽 분산 필요
- 날짜 기반 프리픽스는 트래픽을 한 곳으로 몰아 안티패턴
- UUID나 해시 기반으로 랜덤화하여 무작위성 부여해 물리적 파티션 분산
- 파일 분산을 위한 해시 프리픽스를 생성하여 실제 경로 구성 및 프리사인드 URL 생성

### 기타 고려사항

- 메타데이터와 URL 함께 DB에 저장하여 조회 시 활용
- 대용량 영상(10GB 4K 영상 등) 처리를 위한 멀티파트 업로드 고려
- AWS Media Converter 서비스를 활용해 영상을 여러 비트레이트와 화질로 HLS 형태로 변환 저장


## 🚀 [Tech Dive] Week 2. 대규모 이미지 업로드 시스템 설계 회고

## 1. 아키텍처의 대전환: "서버는 거들 뿐"

우리는 초기 논의에서 가장 중요한 결정을 내렸습니다. "비싼 API 서버를 파일 셔틀로 쓰지 말자"는 것입니다.

- **기존 방식 (Proxy Upload):** `Client → Server → S3`
    - **문제점:** 파일 업로드 중 서버 스레드 블로킹(Blocking), 대역폭 이중 과금(Double Billing).
- **결정된 방식 (Presigned URL):** `Client → S3 (Direct)`
    - **핵심:** 서버는 권한이 담긴 '업로드 티켓(URL)'만 발급하고 빠진다.
    - **효과:** 서버 부하 제로에 수렴, 무제한 수평 확장 가능.


![BitOperations](https://encrypted-tbn2.gstatic.com/licensed-image?q=tbn:ANd9GcSr6FjYZxriUrBJrVLJlH3WsAAxNuFT694BsSJ7MJ8yoTdQyLgJ6wcZ_aPxNcH_hoK5Ome_X7yAWQEruZ4_fEVqJqH_6tPyXbr6bWZivgDlX0vP_oI)

## 2. Deep Dive: 정합성과 신뢰성 (Reliability)

"클라이언트가 S3에 업로드하고 나서, **'나 다했어'라고 말하기 전에 폰이 꺼지면 어떡해?**"라는 질문이 오늘 논의의 하이라이트였습니다.

### A. 고아 객체(Orphan Object) 해결: 이벤트 기반 아키텍처

클라이언트의 네트워크 상태를 신뢰하지 않기로 했습니다. 대신 신뢰할 수 있는 인프라(S3)가 직접 통보하게 만들었습니다.

- **Flow:** `S3 Upload 완료` → `S3 Event` → `SQS` → `Worker Server` → `DB Update`
- **결과:** 사용자의 폰이 꺼지든, 터널을 지나든 상관없이 **업로드된 파일은 100% DB에 동기화**됨.

### B. 중복 요청 방지: 멱등성(Idempotency) 전략

네트워크 오류로 인한 재시도(Retry)가 DB 중복 데이터로 이어지는 것을 막기 위해 **Redis**를 도입했습니다.

- **전략:** `Idempotency-Key` (UUID) 활용.
- **메커니즘:** Redis `SETNX`를 사용하여 **'선점 잠금(Lock)'** 구현.
    - 이미 처리 중인 키(`IN_PROGRESS`)가 오면 `409 Conflict` 또는 대기.
    - 처리 완료된 키(`COMPLETED`)가 오면 저장된 응답(Cached Response)을 그대로 반환.

## 3. 확장성 & 최적화 (Scalability & Optimization)

단순 기능 구현을 넘어, 네이버/카카오급 트래픽을 견디기 위한 **시니어 레벨의 최적화**를 진행했습니다.

### A. S3 성능 병목 해결: 해시 프리픽스 (Hash Prefix)

- **문제:** 날짜 기반 경로(`2025-11-26/...`)는 S3의 특정 파티션에 IO를 집중시켜 `503 Slow Down`을 유발함 (Limit: 3,500 TPS).
- **해결:** 파일 경로 앞에 랜덤 해시값 추가.
    - `bucket/a1b2/uuid_image.jpg` 처럼 엔트로피를 높여 물리 파티션 분산 유도.

### B. 스토리지 비용 절감: On-the-fly Resizing & Deduplication

- **Resizing:** 미리 다 만들어두지 않고, **CloudFront + Lambda@Edge**를 통해 요청 시 실시간 생성 및 캐싱. (Storage 비용 ↓)
- **Deduplication (중복 제거):** 파일의 해시(SHA-256)를 미리 서버에 조회. 이미 있는 파일이면 업로드 스킵(0초 전송). (Bandwidth 비용 ↓)

### C. DB 병목 해결

- **Read:** Master-Slave Replication 적용.
- **Write:** `User_ID` 기반의 **Sharding** 도입으로 쓰기 부하 분산.

## 4. 면접 예상 질문 (Interview Tech-Check)

오늘 설계 내용을 바탕으로 꼬리에 꼬리를 무는 질문들입니다.

1. **Q.** S3 Presigned URL 사용 시 보안 위협(악성 파일)은 어떻게 방어하나요?
    - *A. 업로드 후 Lambda Trigger로 바이러스 스캔 수행 및 Content-Type 강제.*
2. **Q.** SQS 메시지가 중복 전달되면 데이터가 꼬이지 않나요?
    - *A. DB 업데이트 로직을 멱등(Idempotent)하게 설계하여 방어.*
3. **Q.** CDN 캐시가 안 빠져서 옛날 프사가 계속 보이면요?
    - *A. Invalidation 대신 URL Versioning (`img_v2.jpg`) 전략 사용.*

---

한 줄 평:

"단순히 '파일을 올린다'는 기능 구현을 넘어, '어떻게 100만 명의 파일이 유실 없이, 가장 싸고 빠르게 저장될 것인가'를 치열하게 고민한 시간이었습니다. 오늘 설계한 아키텍처는 실무 레벨에서도 즉시 통용될 수준입니다."

```python
# API Server 내부 로직

def get_presigned_url(user_id, original_filename):
    # 1. 파일 식별자 생성 (UUID)
    file_uuid = str(uuid.uuid4()) # 예: "550e8400-e29b..."
    
    # 2. 분산을 위한 해시 프리픽스 생성 (이게 질문하신 포인트!)
    # UUID의 앞부분을 쓰거나 MD5를 돌려서 랜덤한 앞글자 추출
    prefix = hashlib.md5(file_uuid.encode()).hexdigest()[:4] # 예: "a1b2"
    
    # 3. S3에 저장될 진짜 경로(Key) 완성
    # 결과: "a1b2/550e8400-e29b/my_cat.jpg"
    object_key = f"{prefix}/{file_uuid}/{original_filename}"
    
    # 4. AWS S3 Presigned URL 생성
    # 중요: 여기서 Key를 박아버리기 때문에 클라이언트는 딴 데 못 올림
    url = s3_client.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': 'my-instagram-images',
            'Key': object_key, # <--- 여기에 적용됩니다.
            'ContentType': 'image/jpeg'
        },
        ExpiresIn=300
    )
    
    # 5. DB에 메타데이터 미리 저장 (PENDING 상태)
    save_to_db(user_id, object_key, status="PENDING")
    
    return url
```


오늘 스터디에서 다룬 내용들은 실제 네이버, 카카오, 라인, 당근(네카라당) 백엔드 시스템 디자인 면접에서 단골로 나오는 기출 문제들입니다.

오늘 설계한 아키텍처를 바탕으로, 면접관이 파고들 수 있는 질문 리스트를 난이도(Junior vs Senior)와 주제별로 정리해 드리겠습니다. 스터디원들과 서로 질문해보세요.

---

아키텍처 & 트레이드오프 (Architecture)
가장 기본적이지만, '이유'를 설명 못하면 탈락하는 질문들입니다.

Q1. (Junior) 왜 이미지를 서버를 거쳐서 저장하지 않고, Presigned URL을 썼나요?
핵심 답변: 서버 리소스(스레드/메모리) 블로킹 방지, 대역폭 비용 절감(Double billing 방지).
Q2. (Mid) Presigned URL 방식의 단점은 없나요? 보안 문제는요?
핵심 답변: 클라이언트가 통제권을 가지므로 악성 파일 업로드 가능성 존재. -> 해결책: URL 생성 시 Content-Type 고정, S3 업로드 후 트리거되는 Lambda에서 바이러스 스캔 및 파일 포맷 검증 수행.
Q3. (Senior) 썸네일 생성 방식을 '업로드 시 생성(Pre-generation)'과 '요청 시 생성(On-the-fly)' 중 무엇을 선택했고 그 이유는?
핵심 답변: "초기엔 Pre-generation이 쉽지만, 다양한 디바이스 대응과 스토리지 절약을 위해 On-the-fly(CloudFront+Lambda@Edge)를 선택했습니다. 첫 요청 레이턴시는 캐싱으로 상쇄합니다."

---

데이터 정합성 & 비동기 처리 (Consistency)
오늘 가장 깊게 다뤘던 S3 Event Notification 관련 질문입니다.

Q4. (Mid) 클라이언트가 S3 업로드는 성공했는데, 서버에 '완료' 요청을 보내기 전에 앱이 꺼지면 어떻게 되나요? (고아 데이터 문제)
핵심 답변: 클라이언트 요청에 의존하면 데이터 불일치 발생. -> S3 Event Notification + SQS를 사용하여 S3가 서버에 완료 사실을 통보하는 비동기 구조로 해결함.
Q5. (Senior) SQS 메시지가 중복으로 들어오면 어떡하나요? (멱등성)
핵심 답변: DB 업데이트 로직을 멱등하게 설계함(PENDING -> ACTIVE로 바꾸는 건 100번 해도 똑같음). 혹은 메시지 ID를 Redis에 저장해 중복 처리 방지.
---

확장성 & 성능 (Scalability & Performance)
트래픽이 터졌을 때를 가정한 질문입니다.

Q6. (Senior) 특정 날짜나 이벤트 때 업로드가 몰려서 S3가 느려지거나 에러(503)를 뱉습니다. 원인이 뭐고 어떻게 해결하나요?
핵심 답변: S3는 프리픽스(Key 앞부분) 기준으로 파티셔닝됨. 순차적(날짜/ID) 프리픽스는 핫스팟 유발. -> 해시(Hash)나 랜덤 문자열을 프리픽스에 추가하여 분산 저장해야 함.
Q7. (Mid) 메타데이터 DB의 읽기/쓰기가 모두 느려졌습니다. 단계별로 어떻게 확장할 건가요?
핵심 답변: 1단계: Replication(Read 분산), 2단계: Caching(Redis), 3단계: Sharding(User ID 기준 수평 분할) 또는 NoSQL(DynamoDB)로 마이그레이션.
Q8. (Senior) 똑같은 이미지가 수백만 번 업로드되면 스토리지 비용을 어떻게 아끼나요?
핵심 답변: 클라이언트 단에서 파일 해시(MD5/SHA-256)를 계산해 서버에 선조회. 존재하면 업로드 스킵하고 메타데이터만 연결(Dedulication).

---

엣지 케이스 (Edge Cases) - "당황하게 만들기"
면접관이 지원자를 흔들어보기 위해 던지는 질문입니다.

Q9. 만약 사용자가 10GB짜리 4K 동영상을 업로드한다고 하면, 지금 설계(Presigned URL)로 충분한가요?
핵심 답변: 단일 PUT 업로드는 실패 확률이 높고 느림. -> S3 Multipart Upload 기능을 사용해야 함. 파일을 조각내서 병렬 업로드하고, 실패한 조각만 재전송하는 방식으로 변경 필요.
Q10. CDN을 썼는데 사용자가 프로필을 바꿨는데도 옛날 사진이 계속 나온대요. 어떻게 해결하죠?
핵심 답변: CDN Invalidation(비쌈/느림)보다는, 파일 URL 자체를 변경(Versioning)하는 전략 사용. profile.jpg?v=timestamp 또는 profile_v2.jpg.

